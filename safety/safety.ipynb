{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor-based Trip Safety Prediction\n",
    "\n",
    "Predicting dangerous driving (positive label) from series of sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "from featuretools.variable_types import Numeric\n",
    "from featuretools.primitives import make_agg_primitive\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset exploration\n",
    "\n",
    "Explore labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('labels/part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv')\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.groupby(['bookingID']).filter(lambda df:df.shape[0] > 1).sort_values(by=['bookingID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicated detected. Ignoring them to avoid ambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = labels_df[~labels_df.duplicated(['bookingID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = labels_df.label.value_counts()\n",
    "print(label_count)\n",
    "print('Negative ratio: {:.2f}'.format(label_count[0] * 1.0 / labels_df.shape[0]))\n",
    "label_count.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> unbalanced dataset case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "features_p1_df = pd.read_csv('features/part-00000-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')\n",
    "features_p1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features_p1_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize distributions of number of records per bookingID of **positive** (safe driving) vs **negative** (dangerous driving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Num of records')\n",
    "plt.ylabel('Num of bookingID')\n",
    "labels_df.loc[labels_df['label'] == 0].merge(features_p1_df, on='bookingID').bookingID.value_counts().hist(range=[0, 300], edgecolor='gray', color='blue', figsize=[10, 7])\n",
    "labels_df.loc[labels_df['label'] == 1].merge(features_p1_df, on='bookingID').bookingID.value_counts().hist(range=[0, 300], edgecolor='gray', color='red', figsize=[10, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> plot above shows there is no obvious correlation between number of records (sensor readings) and driving safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a pair of random negative and positive sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_neg_bookingID = labels_df.loc[labels_df['label'] == 0].bookingID.sample(1).values[0]\n",
    "random_neg_df = features_p1_df.loc[features_p1_df['bookingID'] == random_neg_bookingID].sort_values(by='second')\n",
    "\n",
    "random_pos_bookingID = labels_df.loc[labels_df['label'] == 1].bookingID.sample(1).values[0]\n",
    "random_pos_df = features_p1_df.loc[features_p1_df['bookingID'] == random_pos_bookingID].sort_values(by='second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_neg_df.plot(title='Safe', kind='line',x='second',y=['Speed', 'Accuracy'], ylim=[0, 800], figsize=[10, 5])\n",
    "\n",
    "random_pos_df.plot(title='Unsafe', kind='line',x='second',y=['Speed', 'Accuracy'], ylim=[0, 800], figsize=[10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_neg_df.plot(title='Safe', kind='line',x='second',y=['acceleration_x', 'acceleration_y', 'acceleration_z'], ylim=[-15, 15], figsize=[10, 5])\n",
    "random_pos_df.plot(title='Unsafe', kind='line',x='second',y=['acceleration_x', 'acceleration_y', 'acceleration_z'], ylim=[-15, 15], figsize=[10, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Generate statistical features for each bookingID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_diff(column):\n",
    "    return column.diff().mean(skipna=True)\n",
    "\n",
    "def max_diff(column):\n",
    "    return column.diff().max(skipna=True)\n",
    "\n",
    "def min_diff(column):\n",
    "    return column.diff().min(skipna=True)\n",
    "\n",
    "def std_diff(column):\n",
    "    return column.diff().std(skipna=True)\n",
    "\n",
    "def mean_diff_abs(column):\n",
    "    return column.diff().abs().mean(skipna=True)\n",
    "\n",
    "def max_diff_abs(column):\n",
    "    return column.diff().abs().max(skipna=True)\n",
    "\n",
    "def min_diff_abs(column):\n",
    "    return column.diff().abs().min(skipna=True)\n",
    "\n",
    "def std_diff_abs(column):\n",
    "    return column.diff().abs().std(skipna=True)\n",
    "\n",
    "\n",
    "# data = pd.Series([1,2,7,3,5,10,3,1])\n",
    "# print(avg_diff(data))\n",
    "# print(std_diff(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_feature_matrix(df):\n",
    "    es = ft.EntitySet('safety_data')\n",
    "    es.entity_from_dataframe(\n",
    "        entity_id='records',\n",
    "        index='id',        \n",
    "        make_index=True,\n",
    "        dataframe=df,        \n",
    "        variable_types={\n",
    "            'Accuracy': vtypes.Numeric,\n",
    "            'Bearing': vtypes.Numeric,\n",
    "            'acceleration_x': vtypes.Numeric,\n",
    "            'acceleration_y': vtypes.Numeric,\n",
    "            'acceleration_z': vtypes.Numeric,\n",
    "            'gyro_x': vtypes.Numeric,\n",
    "            'gyro_y': vtypes.Numeric,\n",
    "            'gyro_z': vtypes.Numeric,\n",
    "            'second': vtypes.Numeric,\n",
    "            'Speed': vtypes.Numeric,\n",
    "        }\n",
    "    )\n",
    "        \n",
    "    es.normalize_entity(\n",
    "        base_entity_id='records',\n",
    "        new_entity_id='bookings',\n",
    "        index='bookingID'    \n",
    "    )\n",
    "    \n",
    "    print(es)\n",
    "    \n",
    "    return ft.dfs(\n",
    "        entityset=es,\n",
    "        target_entity='bookings',\n",
    "        agg_primitives=[\n",
    "            make_agg_primitive(function=mean_diff, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=max_diff, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=min_diff, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=std_diff, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=mean_diff_abs, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=max_diff_abs, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=min_diff_abs, input_types=[Numeric], return_type=Numeric),\n",
    "            make_agg_primitive(function=std_diff_abs, input_types=[Numeric], return_type=Numeric),            \n",
    "            'count', \n",
    "            'mean', \n",
    "            'max', \n",
    "            'min', \n",
    "            'std',\n",
    "        ],\n",
    "        n_jobs=1,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "feature_matrix, feature_names = get_feature_matrix(features_p1_df.copy())\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = feature_matrix.merge(labels_df, on='bookingID')['label']\n",
    "print(feature_matrix.shape)\n",
    "print(feature_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = feature_matrix.values\n",
    "y = feature_labels.values\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(len(feature_names)):\n",
    "    top_feat = \"{}. {}: {:.4g}\".format(f + 1, feature_names[indices[f]].generate_name(), importances[indices[f]])\n",
    "    print(top_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# preprocess\n",
    "# print('Scaling..')\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "classifier = XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='auc',\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X_scaled, y):\n",
    "    probas_ = classifier.fit(X_scaled[train], y[train]).predict_proba(X_scaled[test])\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
